# AISB Project


## Motivation
Many real world applications nowadays are integrating Automatic Speech Recognition (ASR) as part of their workflow. 
Thus it becomes important to look at how these models can be attacked.

(TODO: Add more context)


## Goal
The goal of this project is to attack an ASR model. We distinguish two types of attacks : 

* Untargeted attacks : make the model mistranscribe predictions

* Targeted attacks : transcribe a specific sentence of the attacker's choice.


## OpenAI Whisper
For this project, OpenAI's Whisper model is the target ASR model.


## Demo

Refer to demo notebook for a quick demo.


## Source

All attacks in this repo are based on the paper "There is more than one kind of robustness: Fooling Whisper with adversarial
examples" by Raphael Olivier and Bhiksha Raj.

